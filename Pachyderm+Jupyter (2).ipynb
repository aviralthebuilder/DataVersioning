{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is a documenation of a possible implementation of pachyderm into Jupyter\\nand see whether we can implement data versioning to a certain extent\\nlet us list the various tasks of the mini project and implement it along the way:\\nBefore going into any details, make sure you have the necessary stuff installed\\nfor this.\\n1. We create a repo for the initial raw data. We will call it SMSTRAINING. This\\n   is where we will be putting different versions of input data (since this particular\\n   data set only has two columns, we will be giving more focus to the amount of data,\\n   i.e. varying the the number of rows)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This is a documenation of a possible implementation of pachyderm into Jupyter\n",
    "and see whether we can implement data versioning to a certain extent\n",
    "let us list the various tasks of the mini project and implement it along the way:\n",
    "Before going into any details, make sure you have the necessary stuff installed\n",
    "for this.\n",
    "1. We create a repo for the initial raw data. We will call it SMSTRAINING. This\n",
    "   is where we will be putting different versions of input data (since this particular\n",
    "   data set only has two columns, we will be giving more focus to the amount of data,\n",
    "   i.e. varying the the number of rows)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME        CREATED                SIZE (MASTER) \r\n",
      "SMSTRAINING Less than a second ago 0B            \r\n",
      "jup         2 hours ago            0B            \r\n",
      "test        23 hours ago           0B            \r\n",
      "prep2       25 hours ago           868.1KiB      \r\n",
      "prep        27 hours ago           555KiB        \r\n",
      "sms         27 hours ago           473.5KiB      \r\n",
      "possible    43 hours ago           55B           \r\n",
      "inference   43 hours ago           94B           \r\n",
      "kim         44 hours ago           1.465KiB      \r\n",
      "training    44 hours ago           3.882KiB      \r\n"
     ]
    }
   ],
   "source": [
    "#We create a new Repo through terminal commands\n",
    "\n",
    "!pachctl create repo SMSTRAINING\n",
    "!pachctl list repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    }
   ],
   "source": [
    "#Now we read through the data and add different versions of it to the data set\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"EK0bZ7sBRRiKU2kKs6fx_spamdata-1562916291191.csv\")\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 5572 rows in the data set, so we will put in three versions containg the following sizes:\n",
    "# 4000, 5000, 5572\n",
    "data1 = data[:-1572]\n",
    "data2 = data[:-572]\n",
    "data1.to_csv(\"raw.csv\")\n",
    "!pachctl put file SMSTRAINING@master:raw.csv -f raw.csv --overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we put in the rest of the files\n",
    "data2.to_csv(\"raw.csv\")\n",
    "!pachctl put file SMSTRAINING@master:raw.csv -f raw.csv --overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"raw.csv\")\n",
    "!pachctl put file SMSTRAINING@master:raw.csv -f raw.csv --overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data[:-2572]\n",
    "data3.to_csv(\"raw.csv\")\n",
    "!pachctl put file SMSTRAINING@master:raw.csv -f raw.csv --overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO        BRANCH COMMIT                           PARENT                           STARTED            DURATION           SIZE     \r\n",
      "SMSTRAINING master 1c81adf333904bb8afc7175474f27a21 7f18d48fa86a401896ed2adb0f1fa118 24 seconds ago     Less than a second 268.4KiB \r\n",
      "SMSTRAINING master 7f18d48fa86a401896ed2adb0f1fa118 534750817c0846639aeb930432a45d90 58 seconds ago     Less than a second 494.2KiB \r\n",
      "SMSTRAINING master 534750817c0846639aeb930432a45d90 d5627bffdfb34ea0acbbc53388e4d6b0 About a minute ago Less than a second 444.5KiB \r\n",
      "SMSTRAINING master d5627bffdfb34ea0acbbc53388e4d6b0 <none>                           2 minutes ago      Less than a second 354.6KiB \r\n"
     ]
    }
   ],
   "source": [
    "#We now have four versions of the data, lets have a look at them\n",
    "!pachctl list commit SMSTRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou can look at in the way as if we were given four versions of the raw data where some of them are bad and \\nwe can revert back to the older version using the data versionality service of pachyderm. I have purposefully made \\nthe current most data the worst one to demonstrate it\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "You can look at in the way as if we were given four versions of the raw data where some of them are bad and \n",
    "we can revert back to the older version using the data versionality service of pachyderm. I have purposefully made \n",
    "the current most data the worst one to demonstrate it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. It is now time to preprocess the data, i.e., clean the data and/or apply some feature engineering to it\\n   Like the last version, we will have two versions, one where there are less features than the other one\\n   just to mess around with data a little more.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2. It is now time to preprocess the data, i.e., clean the data and/or apply some feature engineering to it\n",
    "   Like the last version, we will have two versions, one where there are less features than the other one\n",
    "   just to mess around with data a little more.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'playing game today'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version one: a more enhancend cleaning and feature engineering\n",
    "#it is time to clean the text data\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def cleanText(text):\n",
    "    #first convert to lower case\n",
    "    cleanText = text.lower()\n",
    "    #removing the punctuations\n",
    "    cleanText = \"\".join(word for word in cleanText if word not in punctuations)\n",
    "    #time to remove the stopwords as they are basically noise\n",
    "    words = cleanText.split()\n",
    "    words = [word for word in words if word not in stopword]\n",
    "    cleanText = \" \".join(words)\n",
    "    #time to perform lemmatization\n",
    "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "    words = [lem.lemmatize(word, \"n\") for word in words]\n",
    "    return cleanText\n",
    "\n",
    "#testing the function out\n",
    "cleanText(\"I will, be playing a game today!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some ways to get the data out of pachyderm, but they are kind of confusing. We will treat it as an output\n",
    "#the terminal screen and we will save the output in a csv file which we can access easily\n",
    "!pachctl get file SMSTRAINING@master:raw.csv > m.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now read the data normally through the command .read_csv()\n",
    "rawData = pd.read_csv(\"m.csv\", index_col = False)\n",
    "rawData = rawData.drop(\"Unnamed: 0\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now that we have a version of the raw data, we go about pre-processing it and performing some feature engineering\n",
    "import nltk\n",
    "pos_dic = {\"noun\": [\"NNP\" , \"NN\", \"NNS\", \"NNPS\"], \"verb\" : [\"VBZ\", \"VB\", \"VBD\", \"VBN\", \"VBG\"]}\n",
    "\n",
    "def partOfSpeechTag(text, family):\n",
    "    #tokenize the sentence\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    count  = 0\n",
    "    #get the tags of the tokenized words\n",
    "    for tag in tags:\n",
    "        #get the part of speech tag\n",
    "        tag = tag[1]\n",
    "        #check if it is present in the predefined dictionary of ours\n",
    "        if tag in pos_dic[family]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#test the function out\n",
    "partOfSpeechTag(\"They are playing in the ground\", \"verb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessAndFeature(rawData):\n",
    "    rawData[\"cleanText\"] = rawData[\"text\"].apply(cleanText)\n",
    "    rawData[\"rawWordCount\"] = rawData[\"text\"].apply(lambda x : len(x.split()))\n",
    "    rawData[\"cleanWordCount\"] = rawData[\"cleanText\"].apply(lambda x : len(x.split()))\n",
    "    rawData['characterCount'] = rawData['text'].apply(lambda x :len(x))\n",
    "    rawData['characterCountWithoutSpace'] = rawData['text'].apply(lambda x :len(x.replace(\" \", \"\")))\n",
    "    rawData[\"digitOccurrece\"] = rawData[\"text\"].apply(lambda x: sum([1 if word.isdigit() else 0 for word in x.split()]))\n",
    "    rawData[\"nounCount\"] = rawData[\"text\"].apply(lambda x : partOfSpeechTag(x, \"noun\"))\n",
    "    rawData[\"verbCount\"] = rawData[\"text\"].apply(lambda x : partOfSpeechTag(x, \"verb\"))\n",
    "    return rawData\n",
    "rawData = preProcessAndFeature(rawData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>rawWordCount</th>\n",
       "      <th>cleanWordCount</th>\n",
       "      <th>characterCount</th>\n",
       "      <th>characterCountWithoutSpace</th>\n",
       "      <th>digitOccurrece</th>\n",
       "      <th>nounCount</th>\n",
       "      <th>verbCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey darling 3 weeks word back id like ...</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>148</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak treat like aids patent</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>158</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>mobile 11 months u r entitled update latest co...</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>im gonna home soon dont want talk stuff anymor...</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>109</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>six chances win cash 100 20000 pounds txt csh1...</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>urgent 1 week free membership å£100000 prize j...</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>156</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive searching right words thank breather promi...</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>196</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>date sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>xxxmobilemovieclub use credit click wap link n...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>oh kim watching</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>eh u remember 2 spell name yes v naughty make ...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>fine thatåõs way u feel thatåõs way gota b</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>england v macedonia dont miss goalsteam news t...</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>156</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>seriously spell name</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‰Û÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>i‰û÷m going try 2 months ha ha joking</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>ì pay first lar da stock comin</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>aft finish lunch go str lor ard 3 smth lor u f...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>ffffffffff alright way meet sooner</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>forced eat slice im really hungry tho sucks ma...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>144</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>lol always convincing</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>catch bus frying egg make tea eating moms left...</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>im back amp packing car ill let know theres room</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>ahhh work vaguely remember feel like lol</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>ham</td>\n",
       "      <td>Height of Confidence: All the Aeronautics prof...</td>\n",
       "      <td>height confidence aeronautics professors wer c...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>269</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sary just need Tim in the bollox &amp;it hurt him ...</td>\n",
       "      <td>sary need tim bollox hurt lot tol</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>ham</td>\n",
       "      <td>Happy New Year Princess!</td>\n",
       "      <td>happy new year princess</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'll text carlos and let you know, hang on</td>\n",
       "      <td>ill text carlos let know hang</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don't worry, * is easy once have ingredients!</td>\n",
       "      <td>dont worry easy ingredients</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>ham</td>\n",
       "      <td>I love u 2 my little pocy bell I am sorry but ...</td>\n",
       "      <td>love u 2 little pocy bell sorry love u</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok omw now, you at castor?</td>\n",
       "      <td>ok omw castor</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yar lor... Keep raining non stop... Or u wan 2...</td>\n",
       "      <td>yar lor keep raining non stop u wan 2 go elsew...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>spam</td>\n",
       "      <td>Xmas Offer! Latest Motorola, SonyEricsson &amp; No...</td>\n",
       "      <td>xmas offer latest motorola sonyericsson nokia ...</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>159</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>ham</td>\n",
       "      <td>What u mean u almost done? Done wif sleeping? ...</td>\n",
       "      <td>u mean u almost done done wif sleeping tot u g...</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>141</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>ham</td>\n",
       "      <td>7 wonders in My WORLD 7th You 6th Ur style 5th...</td>\n",
       "      <td>7 wonders world 7th 6th ur style 5th ur smile ...</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>153</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>ham</td>\n",
       "      <td>Tonight? Yeah, I'd be down for that</td>\n",
       "      <td>tonight yeah id</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>ham</td>\n",
       "      <td>What should i eat fo lunch senor</td>\n",
       "      <td>eat fo lunch senor</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>ham</td>\n",
       "      <td>He said that he had a right giggle when he saw...</td>\n",
       "      <td>said right giggle saw u would possibly first p...</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>143</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>ham</td>\n",
       "      <td>No break time one... How... I come out n get m...</td>\n",
       "      <td>break time one come n get stuff fr ì</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>spam</td>\n",
       "      <td>Reply to win å£100 weekly! What professional s...</td>\n",
       "      <td>reply win å£100 weekly professional sport tige...</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm there and I can see you, but you can't see...</td>\n",
       "      <td>im see cant see maybe reboot ym seen buzz</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you still have the grinder?</td>\n",
       "      <td>still grinder</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>spam</td>\n",
       "      <td>No 1 POLYPHONIC tone 4 ur mob every week! Just...</td>\n",
       "      <td>1 polyphonic tone 4 ur mob every week txt pt2 ...</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>147</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>ham</td>\n",
       "      <td>Love isn't a decision, it's a feeling. If we c...</td>\n",
       "      <td>love isnt decision feeling could decide love l...</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>126</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>spam</td>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 2...</td>\n",
       "      <td>hot live fantasies call 08707509020 20p per mi...</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>122</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>ham</td>\n",
       "      <td>K.i did't see you.:)k:)where are you now?</td>\n",
       "      <td>ki didt see youkwhere</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>ham</td>\n",
       "      <td>So i'm doing a list of buyers.</td>\n",
       "      <td>im list buyers</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>ham</td>\n",
       "      <td>No idea, I guess we'll work that out an hour a...</td>\n",
       "      <td>idea guess well work hour supposed leave since...</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>157</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mm not entirely sure i understood that text bu...</td>\n",
       "      <td>mm entirely sure understood text hey ho weekend</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>ham</td>\n",
       "      <td>They released vday shirts and when u put it on...</td>\n",
       "      <td>released vday shirts u put makes bottom half n...</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don know..he is watching film in computer..</td>\n",
       "      <td>knowhe watching film computer</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>ham</td>\n",
       "      <td>No b4 Thursday</td>\n",
       "      <td>b4 thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh, then your phone phoned me but it disconnected</td>\n",
       "      <td>oh phone phoned disconnected</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>ham</td>\n",
       "      <td>Id onluy matters when getting on from offcampus</td>\n",
       "      <td>id onluy matters getting offcampus</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6      ham  Even my brother is not like to speak with me. ...   \n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8     spam  WINNER!! As a valued network customer you have...   \n",
       "9     spam  Had your mobile 11 months or more? U R entitle...   \n",
       "10     ham  I'm gonna be home soon and i don't want to tal...   \n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...   \n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...   \n",
       "13     ham  I've been searching for the right words to tha...   \n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...   \n",
       "16     ham                         Oh k...i'm watching here:)   \n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...   \n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...   \n",
       "19    spam  England v Macedonia - dont miss the goals/team...   \n",
       "20     ham          Is that seriously how you spell his name?   \n",
       "21     ham  I‰Û÷m going to try for 2 months ha ha only joking   \n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...   \n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...   \n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...   \n",
       "25     ham  Just forced myself to eat a slice. I'm really ...   \n",
       "26     ham                     Lol your always so convincing.   \n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...   \n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...   \n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...   \n",
       "...    ...                                                ...   \n",
       "2970   ham  Height of Confidence: All the Aeronautics prof...   \n",
       "2971   ham  Sary just need Tim in the bollox &it hurt him ...   \n",
       "2972   ham                           Happy New Year Princess!   \n",
       "2973   ham         I'll text carlos and let you know, hang on   \n",
       "2974   ham      Don't worry, * is easy once have ingredients!   \n",
       "2975   ham  I love u 2 my little pocy bell I am sorry but ...   \n",
       "2976   ham                         Ok omw now, you at castor?   \n",
       "2977   ham  Yar lor... Keep raining non stop... Or u wan 2...   \n",
       "2978  spam  Xmas Offer! Latest Motorola, SonyEricsson & No...   \n",
       "2979   ham  What u mean u almost done? Done wif sleeping? ...   \n",
       "2980   ham  7 wonders in My WORLD 7th You 6th Ur style 5th...   \n",
       "2981   ham                Tonight? Yeah, I'd be down for that   \n",
       "2982   ham                   What should i eat fo lunch senor   \n",
       "2983   ham  He said that he had a right giggle when he saw...   \n",
       "2984   ham  No break time one... How... I come out n get m...   \n",
       "2985  spam  Reply to win å£100 weekly! What professional s...   \n",
       "2986   ham  I'm there and I can see you, but you can't see...   \n",
       "2987   ham                     Do you still have the grinder?   \n",
       "2988  spam  No 1 POLYPHONIC tone 4 ur mob every week! Just...   \n",
       "2989   ham  Love isn't a decision, it's a feeling. If we c...   \n",
       "2990  spam  HOT LIVE FANTASIES call now 08707509020 Just 2...   \n",
       "2991   ham          K.i did't see you.:)k:)where are you now?   \n",
       "2992   ham                     So i'm doing a list of buyers.   \n",
       "2993   ham  No idea, I guess we'll work that out an hour a...   \n",
       "2994   ham  Mm not entirely sure i understood that text bu...   \n",
       "2995   ham  They released vday shirts and when u put it on...   \n",
       "2996   ham        Don know..he is watching film in computer..   \n",
       "2997   ham                                     No b4 Thursday   \n",
       "2998   ham  Oh, then your phone phoned me but it disconnected   \n",
       "2999   ham    Id onluy matters when getting on from offcampus   \n",
       "\n",
       "                                              cleanText  rawWordCount  \\\n",
       "0     go jurong point crazy available bugis n great ...            20   \n",
       "1                               ok lar joking wif u oni             6   \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...            28   \n",
       "3                   u dun say early hor u c already say            11   \n",
       "4           nah dont think goes usf lives around though            13   \n",
       "5     freemsg hey darling 3 weeks word back id like ...            32   \n",
       "6        even brother like speak treat like aids patent            16   \n",
       "7     per request melle melle oru minnaminunginte nu...            26   \n",
       "8     winner valued network customer selected receiv...            26   \n",
       "9     mobile 11 months u r entitled update latest co...            29   \n",
       "10    im gonna home soon dont want talk stuff anymor...            21   \n",
       "11    six chances win cash 100 20000 pounds txt csh1...            26   \n",
       "12    urgent 1 week free membership å£100000 prize j...            26   \n",
       "13    ive searching right words thank breather promi...            37   \n",
       "14                                          date sunday             8   \n",
       "15    xxxmobilemovieclub use credit click wap link n...            19   \n",
       "16                                      oh kim watching             4   \n",
       "17    eh u remember 2 spell name yes v naughty make ...            19   \n",
       "18           fine thatåõs way u feel thatåõs way gota b            13   \n",
       "19    england v macedonia dont miss goalsteam news t...            24   \n",
       "20                                 seriously spell name             8   \n",
       "21                i‰û÷m going try 2 months ha ha joking            11   \n",
       "22                       ì pay first lar da stock comin            11   \n",
       "23    aft finish lunch go str lor ard 3 smth lor u f...            20   \n",
       "24                   ffffffffff alright way meet sooner            11   \n",
       "25    forced eat slice im really hungry tho sucks ma...            28   \n",
       "26                                lol always convincing             5   \n",
       "27    catch bus frying egg make tea eating moms left...            32   \n",
       "28     im back amp packing car ill let know theres room            15   \n",
       "29             ahhh work vaguely remember feel like lol            12   \n",
       "...                                                 ...           ...   \n",
       "2970  height confidence aeronautics professors wer c...            52   \n",
       "2971                  sary need tim bollox hurt lot tol            16   \n",
       "2972                            happy new year princess             4   \n",
       "2973                      ill text carlos let know hang             9   \n",
       "2974                        dont worry easy ingredients             8   \n",
       "2975             love u 2 little pocy bell sorry love u            15   \n",
       "2976                                      ok omw castor             6   \n",
       "2977  yar lor keep raining non stop u wan 2 go elsew...            12   \n",
       "2978  xmas offer latest motorola sonyericsson nokia ...            25   \n",
       "2979  u mean u almost done done wif sleeping tot u g...            33   \n",
       "2980  7 wonders world 7th 6th ur style 5th ur smile ...            30   \n",
       "2981                                    tonight yeah id             7   \n",
       "2982                                 eat fo lunch senor             7   \n",
       "2983  said right giggle saw u would possibly first p...            29   \n",
       "2984               break time one come n get stuff fr ì            14   \n",
       "2985  reply win å£100 weekly professional sport tige...            19   \n",
       "2986          im see cant see maybe reboot ym seen buzz            23   \n",
       "2987                                      still grinder             6   \n",
       "2988  1 polyphonic tone 4 ur mob every week txt pt2 ...            31   \n",
       "2989  love isnt decision feeling could decide love l...            24   \n",
       "2990  hot live fantasies call 08707509020 20p per mi...            24   \n",
       "2991                              ki didt see youkwhere             7   \n",
       "2992                                     im list buyers             7   \n",
       "2993  idea guess well work hour supposed leave since...            30   \n",
       "2994    mm entirely sure understood text hey ho weekend            13   \n",
       "2995  released vday shirts u put makes bottom half n...            21   \n",
       "2996                      knowhe watching film computer             7   \n",
       "2997                                        b4 thursday             3   \n",
       "2998                       oh phone phoned disconnected             9   \n",
       "2999                 id onluy matters getting offcampus             8   \n",
       "\n",
       "      cleanWordCount  characterCount  characterCountWithoutSpace  \\\n",
       "0                 16             111                          92   \n",
       "1                  6              29                          24   \n",
       "2                 23             155                         128   \n",
       "3                  9              49                          39   \n",
       "4                  8              61                          49   \n",
       "5                 19             148                         117   \n",
       "6                  8              77                          62   \n",
       "7                 16             160                         135   \n",
       "8                 18             158                         133   \n",
       "9                 18             154                         126   \n",
       "10                15             109                          89   \n",
       "11                21             136                         111   \n",
       "12                17             156                         131   \n",
       "13                16             196                         160   \n",
       "14                 2              35                          28   \n",
       "15                12             149                         131   \n",
       "16                 3              26                          23   \n",
       "17                12              81                          63   \n",
       "18                 9              58                          46   \n",
       "19                20             156                         133   \n",
       "20                 3              41                          34   \n",
       "21                 8              49                          39   \n",
       "22                 7              53                          43   \n",
       "23                15              88                          69   \n",
       "24                 5              57                          47   \n",
       "25                17             144                         117   \n",
       "26                 3              30                          26   \n",
       "27                12             134                         103   \n",
       "28                10              75                          61   \n",
       "29                 7              64                          53   \n",
       "...              ...             ...                         ...   \n",
       "2970              31             269                         218   \n",
       "2971               7              65                          50   \n",
       "2972               4              24                          21   \n",
       "2973               6              42                          34   \n",
       "2974               4              45                          38   \n",
       "2975               9              54                          40   \n",
       "2976               3              26                          21   \n",
       "2977              11              60                          49   \n",
       "2978              18             159                         135   \n",
       "2979              22             141                         109   \n",
       "2980              26             153                         124   \n",
       "2981               3              35                          29   \n",
       "2982               4              32                          26   \n",
       "2983              13             143                         114   \n",
       "2984               9              60                          47   \n",
       "2985              14             107                          89   \n",
       "2986               9              96                          74   \n",
       "2987               2              30                          25   \n",
       "2988              24             147                         117   \n",
       "2989              13             126                         103   \n",
       "2990              20             122                          99   \n",
       "2991               4              41                          35   \n",
       "2992               3              30                          24   \n",
       "2993              15             157                         128   \n",
       "2994               8              71                          59   \n",
       "2995              12             112                          92   \n",
       "2996               4              43                          37   \n",
       "2997               2              14                          12   \n",
       "2998               4              49                          41   \n",
       "2999               5              47                          40   \n",
       "\n",
       "      digitOccurrece  nounCount  verbCount  \n",
       "0                  0         10          1  \n",
       "1                  0          4          0  \n",
       "2                  2         13          3  \n",
       "3                  0          3          0  \n",
       "4                  0          1          4  \n",
       "5                  1          9          8  \n",
       "6                  0          3          2  \n",
       "7                  0         12          4  \n",
       "8                  1         11          6  \n",
       "9                  2         11          3  \n",
       "10                 0          3          8  \n",
       "11                 2         11          2  \n",
       "12                 2         15          1  \n",
       "13                 0          6          7  \n",
       "14                 0          4          0  \n",
       "15                 0         11          2  \n",
       "16                 0          1          1  \n",
       "17                 1          5          4  \n",
       "18                 0          5          1  \n",
       "19                 2         14          0  \n",
       "20                 0          1          1  \n",
       "21                 1          2          5  \n",
       "22                 0          3          1  \n",
       "23                 1          7          0  \n",
       "24                 0          3          1  \n",
       "25                 0          4          7  \n",
       "26                 0          0          1  \n",
       "27                 0         11          4  \n",
       "28                 0          3          4  \n",
       "29                 0          3          2  \n",
       "...              ...        ...        ...  \n",
       "2970               2         20          7  \n",
       "2971               0          3          2  \n",
       "2972               0          3          0  \n",
       "2973               0          1          4  \n",
       "2974               0          1          2  \n",
       "2975               1          1          0  \n",
       "2976               0          2          0  \n",
       "2977               1          6          1  \n",
       "2978               2         15          1  \n",
       "2979               1         12          5  \n",
       "2980               1         17          0  \n",
       "2981               0          1          1  \n",
       "2982               0          3          1  \n",
       "2983               0          3          5  \n",
       "2984               0          5          1  \n",
       "2985               1          8          3  \n",
       "2986               0          2          4  \n",
       "2987               0          1          1  \n",
       "2988               3         13          2  \n",
       "2989               0          5          5  \n",
       "2990               3         13          1  \n",
       "2991               0          4          0  \n",
       "2992               0          2          1  \n",
       "2993               0          4          6  \n",
       "2994               0          7          1  \n",
       "2995               0          3          3  \n",
       "2996               0          4          2  \n",
       "2997               0          2          0  \n",
       "2998               0          1          2  \n",
       "2999               0          4          1  \n",
       "\n",
       "[3000 rows x 10 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now this is the preprocesssed data\n",
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is now time to store the more versioned data in another repo called CLEANEDDATA\n",
    "!pachctl create repo CLEANDATA\n",
    "rawData.to_csv(\"processedData.csv\")\n",
    "!pachctl put file CLEANDATA@master:processedData.csv -f processedData.csv --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME        CREATED        SIZE (MASTER) \r\n",
      "CLEANDATA   36 seconds ago 483.7KiB      \r\n",
      "SMSTRAINING 23 minutes ago 268.4KiB      \r\n",
      "jup         2 hours ago    0B            \r\n",
      "test        24 hours ago   0B            \r\n",
      "prep2       26 hours ago   868.1KiB      \r\n",
      "prep        28 hours ago   555KiB        \r\n",
      "sms         28 hours ago   473.5KiB      \r\n",
      "possible    44 hours ago   55B           \r\n",
      "inference   44 hours ago   94B           \r\n",
      "kim         44 hours ago   1.465KiB      \r\n",
      "training    45 hours ago   3.882KiB      \r\n"
     ]
    }
   ],
   "source": [
    "#Let us just make sure that the commit was successful\n",
    "!pachctl list repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, the file was successfully committed into the repo\n",
    "#Now as our second step of the overall second step, we put another version of the text into the repo which is not that\n",
    "#much preprocessed\n",
    "def preProcessAndFeatureVersion2(rawData):\n",
    "    rawData[\"cleanText\"] = rawData[\"text\"].apply(cleanText)\n",
    "    rawData[\"cleanWordCount\"] = rawData[\"cleanText\"].apply(lambda x : len(x.split()))\n",
    "    rawData[\"nounCount\"] = rawData[\"text\"].apply(lambda x : partOfSpeechTag(x, \"noun\"))\n",
    "    rawData[\"verbCount\"] = rawData[\"text\"].apply(lambda x : partOfSpeechTag(x, \"verb\"))\n",
    "    return rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>cleanWordCount</th>\n",
       "      <th>nounCount</th>\n",
       "      <th>verbCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey darling 3 weeks word back id like ...</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak treat like aids patent</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>mobile 11 months u r entitled update latest co...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>im gonna home soon dont want talk stuff anymor...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>six chances win cash 100 20000 pounds txt csh1...</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>urgent 1 week free membership å£100000 prize j...</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive searching right words thank breather promi...</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>date sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>xxxmobilemovieclub use credit click wap link n...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>oh kim watching</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>eh u remember 2 spell name yes v naughty make ...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>fine thatåõs way u feel thatåõs way gota b</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>england v macedonia dont miss goalsteam news t...</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>seriously spell name</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‰Û÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>i‰û÷m going try 2 months ha ha joking</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>ì pay first lar da stock comin</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>aft finish lunch go str lor ard 3 smth lor u f...</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>ffffffffff alright way meet sooner</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>forced eat slice im really hungry tho sucks ma...</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>lol always convincing</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>catch bus frying egg make tea eating moms left...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>im back amp packing car ill let know theres room</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>ahhh work vaguely remember feel like lol</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>ham</td>\n",
       "      <td>Height of Confidence: All the Aeronautics prof...</td>\n",
       "      <td>height confidence aeronautics professors wer c...</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sary just need Tim in the bollox &amp;it hurt him ...</td>\n",
       "      <td>sary need tim bollox hurt lot tol</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>ham</td>\n",
       "      <td>Happy New Year Princess!</td>\n",
       "      <td>happy new year princess</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'll text carlos and let you know, hang on</td>\n",
       "      <td>ill text carlos let know hang</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don't worry, * is easy once have ingredients!</td>\n",
       "      <td>dont worry easy ingredients</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>ham</td>\n",
       "      <td>I love u 2 my little pocy bell I am sorry but ...</td>\n",
       "      <td>love u 2 little pocy bell sorry love u</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok omw now, you at castor?</td>\n",
       "      <td>ok omw castor</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yar lor... Keep raining non stop... Or u wan 2...</td>\n",
       "      <td>yar lor keep raining non stop u wan 2 go elsew...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>spam</td>\n",
       "      <td>Xmas Offer! Latest Motorola, SonyEricsson &amp; No...</td>\n",
       "      <td>xmas offer latest motorola sonyericsson nokia ...</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>ham</td>\n",
       "      <td>What u mean u almost done? Done wif sleeping? ...</td>\n",
       "      <td>u mean u almost done done wif sleeping tot u g...</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>ham</td>\n",
       "      <td>7 wonders in My WORLD 7th You 6th Ur style 5th...</td>\n",
       "      <td>7 wonders world 7th 6th ur style 5th ur smile ...</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>ham</td>\n",
       "      <td>Tonight? Yeah, I'd be down for that</td>\n",
       "      <td>tonight yeah id</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>ham</td>\n",
       "      <td>What should i eat fo lunch senor</td>\n",
       "      <td>eat fo lunch senor</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>ham</td>\n",
       "      <td>He said that he had a right giggle when he saw...</td>\n",
       "      <td>said right giggle saw u would possibly first p...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>ham</td>\n",
       "      <td>No break time one... How... I come out n get m...</td>\n",
       "      <td>break time one come n get stuff fr ì</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>spam</td>\n",
       "      <td>Reply to win å£100 weekly! What professional s...</td>\n",
       "      <td>reply win å£100 weekly professional sport tige...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm there and I can see you, but you can't see...</td>\n",
       "      <td>im see cant see maybe reboot ym seen buzz</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you still have the grinder?</td>\n",
       "      <td>still grinder</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>spam</td>\n",
       "      <td>No 1 POLYPHONIC tone 4 ur mob every week! Just...</td>\n",
       "      <td>1 polyphonic tone 4 ur mob every week txt pt2 ...</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>ham</td>\n",
       "      <td>Love isn't a decision, it's a feeling. If we c...</td>\n",
       "      <td>love isnt decision feeling could decide love l...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>spam</td>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 2...</td>\n",
       "      <td>hot live fantasies call 08707509020 20p per mi...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>ham</td>\n",
       "      <td>K.i did't see you.:)k:)where are you now?</td>\n",
       "      <td>ki didt see youkwhere</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>ham</td>\n",
       "      <td>So i'm doing a list of buyers.</td>\n",
       "      <td>im list buyers</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>ham</td>\n",
       "      <td>No idea, I guess we'll work that out an hour a...</td>\n",
       "      <td>idea guess well work hour supposed leave since...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mm not entirely sure i understood that text bu...</td>\n",
       "      <td>mm entirely sure understood text hey ho weekend</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>ham</td>\n",
       "      <td>They released vday shirts and when u put it on...</td>\n",
       "      <td>released vday shirts u put makes bottom half n...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don know..he is watching film in computer..</td>\n",
       "      <td>knowhe watching film computer</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>ham</td>\n",
       "      <td>No b4 Thursday</td>\n",
       "      <td>b4 thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh, then your phone phoned me but it disconnected</td>\n",
       "      <td>oh phone phoned disconnected</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>ham</td>\n",
       "      <td>Id onluy matters when getting on from offcampus</td>\n",
       "      <td>id onluy matters getting offcampus</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6      ham  Even my brother is not like to speak with me. ...   \n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8     spam  WINNER!! As a valued network customer you have...   \n",
       "9     spam  Had your mobile 11 months or more? U R entitle...   \n",
       "10     ham  I'm gonna be home soon and i don't want to tal...   \n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...   \n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...   \n",
       "13     ham  I've been searching for the right words to tha...   \n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...   \n",
       "16     ham                         Oh k...i'm watching here:)   \n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...   \n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...   \n",
       "19    spam  England v Macedonia - dont miss the goals/team...   \n",
       "20     ham          Is that seriously how you spell his name?   \n",
       "21     ham  I‰Û÷m going to try for 2 months ha ha only joking   \n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...   \n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...   \n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...   \n",
       "25     ham  Just forced myself to eat a slice. I'm really ...   \n",
       "26     ham                     Lol your always so convincing.   \n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...   \n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...   \n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...   \n",
       "...    ...                                                ...   \n",
       "2970   ham  Height of Confidence: All the Aeronautics prof...   \n",
       "2971   ham  Sary just need Tim in the bollox &it hurt him ...   \n",
       "2972   ham                           Happy New Year Princess!   \n",
       "2973   ham         I'll text carlos and let you know, hang on   \n",
       "2974   ham      Don't worry, * is easy once have ingredients!   \n",
       "2975   ham  I love u 2 my little pocy bell I am sorry but ...   \n",
       "2976   ham                         Ok omw now, you at castor?   \n",
       "2977   ham  Yar lor... Keep raining non stop... Or u wan 2...   \n",
       "2978  spam  Xmas Offer! Latest Motorola, SonyEricsson & No...   \n",
       "2979   ham  What u mean u almost done? Done wif sleeping? ...   \n",
       "2980   ham  7 wonders in My WORLD 7th You 6th Ur style 5th...   \n",
       "2981   ham                Tonight? Yeah, I'd be down for that   \n",
       "2982   ham                   What should i eat fo lunch senor   \n",
       "2983   ham  He said that he had a right giggle when he saw...   \n",
       "2984   ham  No break time one... How... I come out n get m...   \n",
       "2985  spam  Reply to win å£100 weekly! What professional s...   \n",
       "2986   ham  I'm there and I can see you, but you can't see...   \n",
       "2987   ham                     Do you still have the grinder?   \n",
       "2988  spam  No 1 POLYPHONIC tone 4 ur mob every week! Just...   \n",
       "2989   ham  Love isn't a decision, it's a feeling. If we c...   \n",
       "2990  spam  HOT LIVE FANTASIES call now 08707509020 Just 2...   \n",
       "2991   ham          K.i did't see you.:)k:)where are you now?   \n",
       "2992   ham                     So i'm doing a list of buyers.   \n",
       "2993   ham  No idea, I guess we'll work that out an hour a...   \n",
       "2994   ham  Mm not entirely sure i understood that text bu...   \n",
       "2995   ham  They released vday shirts and when u put it on...   \n",
       "2996   ham        Don know..he is watching film in computer..   \n",
       "2997   ham                                     No b4 Thursday   \n",
       "2998   ham  Oh, then your phone phoned me but it disconnected   \n",
       "2999   ham    Id onluy matters when getting on from offcampus   \n",
       "\n",
       "                                              cleanText  cleanWordCount  \\\n",
       "0     go jurong point crazy available bugis n great ...              16   \n",
       "1                               ok lar joking wif u oni               6   \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...              23   \n",
       "3                   u dun say early hor u c already say               9   \n",
       "4           nah dont think goes usf lives around though               8   \n",
       "5     freemsg hey darling 3 weeks word back id like ...              19   \n",
       "6        even brother like speak treat like aids patent               8   \n",
       "7     per request melle melle oru minnaminunginte nu...              16   \n",
       "8     winner valued network customer selected receiv...              18   \n",
       "9     mobile 11 months u r entitled update latest co...              18   \n",
       "10    im gonna home soon dont want talk stuff anymor...              15   \n",
       "11    six chances win cash 100 20000 pounds txt csh1...              21   \n",
       "12    urgent 1 week free membership å£100000 prize j...              17   \n",
       "13    ive searching right words thank breather promi...              16   \n",
       "14                                          date sunday               2   \n",
       "15    xxxmobilemovieclub use credit click wap link n...              12   \n",
       "16                                      oh kim watching               3   \n",
       "17    eh u remember 2 spell name yes v naughty make ...              12   \n",
       "18           fine thatåõs way u feel thatåõs way gota b               9   \n",
       "19    england v macedonia dont miss goalsteam news t...              20   \n",
       "20                                 seriously spell name               3   \n",
       "21                i‰û÷m going try 2 months ha ha joking               8   \n",
       "22                       ì pay first lar da stock comin               7   \n",
       "23    aft finish lunch go str lor ard 3 smth lor u f...              15   \n",
       "24                   ffffffffff alright way meet sooner               5   \n",
       "25    forced eat slice im really hungry tho sucks ma...              17   \n",
       "26                                lol always convincing               3   \n",
       "27    catch bus frying egg make tea eating moms left...              12   \n",
       "28     im back amp packing car ill let know theres room              10   \n",
       "29             ahhh work vaguely remember feel like lol               7   \n",
       "...                                                 ...             ...   \n",
       "2970  height confidence aeronautics professors wer c...              31   \n",
       "2971                  sary need tim bollox hurt lot tol               7   \n",
       "2972                            happy new year princess               4   \n",
       "2973                      ill text carlos let know hang               6   \n",
       "2974                        dont worry easy ingredients               4   \n",
       "2975             love u 2 little pocy bell sorry love u               9   \n",
       "2976                                      ok omw castor               3   \n",
       "2977  yar lor keep raining non stop u wan 2 go elsew...              11   \n",
       "2978  xmas offer latest motorola sonyericsson nokia ...              18   \n",
       "2979  u mean u almost done done wif sleeping tot u g...              22   \n",
       "2980  7 wonders world 7th 6th ur style 5th ur smile ...              26   \n",
       "2981                                    tonight yeah id               3   \n",
       "2982                                 eat fo lunch senor               4   \n",
       "2983  said right giggle saw u would possibly first p...              13   \n",
       "2984               break time one come n get stuff fr ì               9   \n",
       "2985  reply win å£100 weekly professional sport tige...              14   \n",
       "2986          im see cant see maybe reboot ym seen buzz               9   \n",
       "2987                                      still grinder               2   \n",
       "2988  1 polyphonic tone 4 ur mob every week txt pt2 ...              24   \n",
       "2989  love isnt decision feeling could decide love l...              13   \n",
       "2990  hot live fantasies call 08707509020 20p per mi...              20   \n",
       "2991                              ki didt see youkwhere               4   \n",
       "2992                                     im list buyers               3   \n",
       "2993  idea guess well work hour supposed leave since...              15   \n",
       "2994    mm entirely sure understood text hey ho weekend               8   \n",
       "2995  released vday shirts u put makes bottom half n...              12   \n",
       "2996                      knowhe watching film computer               4   \n",
       "2997                                        b4 thursday               2   \n",
       "2998                       oh phone phoned disconnected               4   \n",
       "2999                 id onluy matters getting offcampus               5   \n",
       "\n",
       "      nounCount  verbCount  \n",
       "0            10          1  \n",
       "1             4          0  \n",
       "2            13          3  \n",
       "3             3          0  \n",
       "4             1          4  \n",
       "5             9          8  \n",
       "6             3          2  \n",
       "7            12          4  \n",
       "8            11          6  \n",
       "9            11          3  \n",
       "10            3          8  \n",
       "11           11          2  \n",
       "12           15          1  \n",
       "13            6          7  \n",
       "14            4          0  \n",
       "15           11          2  \n",
       "16            1          1  \n",
       "17            5          4  \n",
       "18            5          1  \n",
       "19           14          0  \n",
       "20            1          1  \n",
       "21            2          5  \n",
       "22            3          1  \n",
       "23            7          0  \n",
       "24            3          1  \n",
       "25            4          7  \n",
       "26            0          1  \n",
       "27           11          4  \n",
       "28            3          4  \n",
       "29            3          2  \n",
       "...         ...        ...  \n",
       "2970         20          7  \n",
       "2971          3          2  \n",
       "2972          3          0  \n",
       "2973          1          4  \n",
       "2974          1          2  \n",
       "2975          1          0  \n",
       "2976          2          0  \n",
       "2977          6          1  \n",
       "2978         15          1  \n",
       "2979         12          5  \n",
       "2980         17          0  \n",
       "2981          1          1  \n",
       "2982          3          1  \n",
       "2983          3          5  \n",
       "2984          5          1  \n",
       "2985          8          3  \n",
       "2986          2          4  \n",
       "2987          1          1  \n",
       "2988         13          2  \n",
       "2989          5          5  \n",
       "2990         13          1  \n",
       "2991          4          0  \n",
       "2992          2          1  \n",
       "2993          4          6  \n",
       "2994          7          1  \n",
       "2995          3          3  \n",
       "2996          4          2  \n",
       "2997          2          0  \n",
       "2998          1          2  \n",
       "2999          4          1  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondVersionRawData = pd.read_csv(\"m.csv\", index_col = False)\n",
    "secondVersionRawData = secondVersionRawData.drop(\"Unnamed: 0\", axis = 1)\n",
    "secondVersionRawData = preProcessAndFeatureVersion2(secondVersionRawData)\n",
    "#check whether it came out as expected\n",
    "secondVersionRawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yes the second version has also come out correctly, now it is time to commit this as well\n",
    "secondVersionRawData.to_csv(\"processedData.csv\")\n",
    "!pachctl put file CLEANDATA@master:processedData.csv -f processedData.csv --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME        CREATED        SIZE (MASTER) \r\n",
      "CLEANDATA   6 minutes ago  450.9KiB      \r\n",
      "SMSTRAINING 29 minutes ago 268.4KiB      \r\n",
      "jup         2 hours ago    0B            \r\n",
      "test        24 hours ago   0B            \r\n",
      "prep2       26 hours ago   868.1KiB      \r\n",
      "prep        28 hours ago   555KiB        \r\n",
      "sms         28 hours ago   473.5KiB      \r\n",
      "possible    44 hours ago   55B           \r\n",
      "inference   44 hours ago   94B           \r\n",
      "kim         45 hours ago   1.465KiB      \r\n",
      "training    45 hours ago   3.882KiB      \r\n"
     ]
    }
   ],
   "source": [
    "#Let us just make sure that the commit was successful\n",
    "!pachctl list repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as you can see, it was successful as the size of the repo CLEANDATA changed from roughly 483 KiB to 450 KiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3. Now that we have access to the preprocessed data it is time to analyze it a bit more by some extensive Feature \\n   Engineering methods such as TfIDF and so on.\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3. Now that we have access to the preprocessed data it is time to analyze it a bit more by some extensive Feature \n",
    "   Engineering methods such as TfIDF and so on.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO      BRANCH COMMIT                           PARENT                           STARTED        DURATION           SIZE     \r\n",
      "CLEANDATA master a6f41f8ba4a54824a5a9e4bf948a9bb5 b290f1d7f77c487cb4bcc066ba731ab5 7 minutes ago  Less than a second 450.9KiB \r\n",
      "CLEANDATA master b290f1d7f77c487cb4bcc066ba731ab5 <none>                           13 minutes ago Less than a second 483.7KiB \r\n"
     ]
    }
   ],
   "source": [
    "#first let us have a look at the commits that have been made to the CLEANDATA\n",
    "!pachctl list commit CLEANDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are two versions of the preprocessed data: the idea here was to showcase an event where some changes have been \n",
    "#made to a certain preprocessing model like inclusion of certain features and how we can refer back to the previous\n",
    "#data so easly through Pachyderm\n",
    "\n",
    "#our first step is to access the file from the CLEANDATA REPO\n",
    "!pachctl get file CLEANDATA@master:processedData.csv > pre.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>cleanWordCount</th>\n",
       "      <th>nounCount</th>\n",
       "      <th>verbCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey darling 3 weeks word back id like ...</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak treat like aids patent</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>mobile 11 months u r entitled update latest co...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>im gonna home soon dont want talk stuff anymor...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>six chances win cash 100 20000 pounds txt csh1...</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>urgent 1 week free membership å£100000 prize j...</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive searching right words thank breather promi...</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>date sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>xxxmobilemovieclub use credit click wap link n...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>oh kim watching</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>eh u remember 2 spell name yes v naughty make ...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>fine thatåõs way u feel thatåõs way gota b</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>england v macedonia dont miss goalsteam news t...</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>seriously spell name</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‰Û÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>i‰û÷m going try 2 months ha ha joking</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>ì pay first lar da stock comin</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>aft finish lunch go str lor ard 3 smth lor u f...</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>ffffffffff alright way meet sooner</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>forced eat slice im really hungry tho sucks ma...</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>lol always convincing</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>catch bus frying egg make tea eating moms left...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>im back amp packing car ill let know theres room</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>ahhh work vaguely remember feel like lol</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>ham</td>\n",
       "      <td>Height of Confidence: All the Aeronautics prof...</td>\n",
       "      <td>height confidence aeronautics professors wer c...</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sary just need Tim in the bollox &amp;it hurt him ...</td>\n",
       "      <td>sary need tim bollox hurt lot tol</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>ham</td>\n",
       "      <td>Happy New Year Princess!</td>\n",
       "      <td>happy new year princess</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'll text carlos and let you know, hang on</td>\n",
       "      <td>ill text carlos let know hang</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don't worry, * is easy once have ingredients!</td>\n",
       "      <td>dont worry easy ingredients</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>ham</td>\n",
       "      <td>I love u 2 my little pocy bell I am sorry but ...</td>\n",
       "      <td>love u 2 little pocy bell sorry love u</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok omw now, you at castor?</td>\n",
       "      <td>ok omw castor</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yar lor... Keep raining non stop... Or u wan 2...</td>\n",
       "      <td>yar lor keep raining non stop u wan 2 go elsew...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>spam</td>\n",
       "      <td>Xmas Offer! Latest Motorola, SonyEricsson &amp; No...</td>\n",
       "      <td>xmas offer latest motorola sonyericsson nokia ...</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>ham</td>\n",
       "      <td>What u mean u almost done? Done wif sleeping? ...</td>\n",
       "      <td>u mean u almost done done wif sleeping tot u g...</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>ham</td>\n",
       "      <td>7 wonders in My WORLD 7th You 6th Ur style 5th...</td>\n",
       "      <td>7 wonders world 7th 6th ur style 5th ur smile ...</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>ham</td>\n",
       "      <td>Tonight? Yeah, I'd be down for that</td>\n",
       "      <td>tonight yeah id</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>ham</td>\n",
       "      <td>What should i eat fo lunch senor</td>\n",
       "      <td>eat fo lunch senor</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>ham</td>\n",
       "      <td>He said that he had a right giggle when he saw...</td>\n",
       "      <td>said right giggle saw u would possibly first p...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>ham</td>\n",
       "      <td>No break time one... How... I come out n get m...</td>\n",
       "      <td>break time one come n get stuff fr ì</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>spam</td>\n",
       "      <td>Reply to win å£100 weekly! What professional s...</td>\n",
       "      <td>reply win å£100 weekly professional sport tige...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm there and I can see you, but you can't see...</td>\n",
       "      <td>im see cant see maybe reboot ym seen buzz</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do you still have the grinder?</td>\n",
       "      <td>still grinder</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>spam</td>\n",
       "      <td>No 1 POLYPHONIC tone 4 ur mob every week! Just...</td>\n",
       "      <td>1 polyphonic tone 4 ur mob every week txt pt2 ...</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>ham</td>\n",
       "      <td>Love isn't a decision, it's a feeling. If we c...</td>\n",
       "      <td>love isnt decision feeling could decide love l...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>spam</td>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 2...</td>\n",
       "      <td>hot live fantasies call 08707509020 20p per mi...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>ham</td>\n",
       "      <td>K.i did't see you.:)k:)where are you now?</td>\n",
       "      <td>ki didt see youkwhere</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>ham</td>\n",
       "      <td>So i'm doing a list of buyers.</td>\n",
       "      <td>im list buyers</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>ham</td>\n",
       "      <td>No idea, I guess we'll work that out an hour a...</td>\n",
       "      <td>idea guess well work hour supposed leave since...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mm not entirely sure i understood that text bu...</td>\n",
       "      <td>mm entirely sure understood text hey ho weekend</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>ham</td>\n",
       "      <td>They released vday shirts and when u put it on...</td>\n",
       "      <td>released vday shirts u put makes bottom half n...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don know..he is watching film in computer..</td>\n",
       "      <td>knowhe watching film computer</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>ham</td>\n",
       "      <td>No b4 Thursday</td>\n",
       "      <td>b4 thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh, then your phone phoned me but it disconnected</td>\n",
       "      <td>oh phone phoned disconnected</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>ham</td>\n",
       "      <td>Id onluy matters when getting on from offcampus</td>\n",
       "      <td>id onluy matters getting offcampus</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6      ham  Even my brother is not like to speak with me. ...   \n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8     spam  WINNER!! As a valued network customer you have...   \n",
       "9     spam  Had your mobile 11 months or more? U R entitle...   \n",
       "10     ham  I'm gonna be home soon and i don't want to tal...   \n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...   \n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...   \n",
       "13     ham  I've been searching for the right words to tha...   \n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...   \n",
       "16     ham                         Oh k...i'm watching here:)   \n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...   \n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...   \n",
       "19    spam  England v Macedonia - dont miss the goals/team...   \n",
       "20     ham          Is that seriously how you spell his name?   \n",
       "21     ham  I‰Û÷m going to try for 2 months ha ha only joking   \n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...   \n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...   \n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...   \n",
       "25     ham  Just forced myself to eat a slice. I'm really ...   \n",
       "26     ham                     Lol your always so convincing.   \n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...   \n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...   \n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...   \n",
       "...    ...                                                ...   \n",
       "2970   ham  Height of Confidence: All the Aeronautics prof...   \n",
       "2971   ham  Sary just need Tim in the bollox &it hurt him ...   \n",
       "2972   ham                           Happy New Year Princess!   \n",
       "2973   ham         I'll text carlos and let you know, hang on   \n",
       "2974   ham      Don't worry, * is easy once have ingredients!   \n",
       "2975   ham  I love u 2 my little pocy bell I am sorry but ...   \n",
       "2976   ham                         Ok omw now, you at castor?   \n",
       "2977   ham  Yar lor... Keep raining non stop... Or u wan 2...   \n",
       "2978  spam  Xmas Offer! Latest Motorola, SonyEricsson & No...   \n",
       "2979   ham  What u mean u almost done? Done wif sleeping? ...   \n",
       "2980   ham  7 wonders in My WORLD 7th You 6th Ur style 5th...   \n",
       "2981   ham                Tonight? Yeah, I'd be down for that   \n",
       "2982   ham                   What should i eat fo lunch senor   \n",
       "2983   ham  He said that he had a right giggle when he saw...   \n",
       "2984   ham  No break time one... How... I come out n get m...   \n",
       "2985  spam  Reply to win å£100 weekly! What professional s...   \n",
       "2986   ham  I'm there and I can see you, but you can't see...   \n",
       "2987   ham                     Do you still have the grinder?   \n",
       "2988  spam  No 1 POLYPHONIC tone 4 ur mob every week! Just...   \n",
       "2989   ham  Love isn't a decision, it's a feeling. If we c...   \n",
       "2990  spam  HOT LIVE FANTASIES call now 08707509020 Just 2...   \n",
       "2991   ham          K.i did't see you.:)k:)where are you now?   \n",
       "2992   ham                     So i'm doing a list of buyers.   \n",
       "2993   ham  No idea, I guess we'll work that out an hour a...   \n",
       "2994   ham  Mm not entirely sure i understood that text bu...   \n",
       "2995   ham  They released vday shirts and when u put it on...   \n",
       "2996   ham        Don know..he is watching film in computer..   \n",
       "2997   ham                                     No b4 Thursday   \n",
       "2998   ham  Oh, then your phone phoned me but it disconnected   \n",
       "2999   ham    Id onluy matters when getting on from offcampus   \n",
       "\n",
       "                                              cleanText  cleanWordCount  \\\n",
       "0     go jurong point crazy available bugis n great ...              16   \n",
       "1                               ok lar joking wif u oni               6   \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...              23   \n",
       "3                   u dun say early hor u c already say               9   \n",
       "4           nah dont think goes usf lives around though               8   \n",
       "5     freemsg hey darling 3 weeks word back id like ...              19   \n",
       "6        even brother like speak treat like aids patent               8   \n",
       "7     per request melle melle oru minnaminunginte nu...              16   \n",
       "8     winner valued network customer selected receiv...              18   \n",
       "9     mobile 11 months u r entitled update latest co...              18   \n",
       "10    im gonna home soon dont want talk stuff anymor...              15   \n",
       "11    six chances win cash 100 20000 pounds txt csh1...              21   \n",
       "12    urgent 1 week free membership å£100000 prize j...              17   \n",
       "13    ive searching right words thank breather promi...              16   \n",
       "14                                          date sunday               2   \n",
       "15    xxxmobilemovieclub use credit click wap link n...              12   \n",
       "16                                      oh kim watching               3   \n",
       "17    eh u remember 2 spell name yes v naughty make ...              12   \n",
       "18           fine thatåõs way u feel thatåõs way gota b               9   \n",
       "19    england v macedonia dont miss goalsteam news t...              20   \n",
       "20                                 seriously spell name               3   \n",
       "21                i‰û÷m going try 2 months ha ha joking               8   \n",
       "22                       ì pay first lar da stock comin               7   \n",
       "23    aft finish lunch go str lor ard 3 smth lor u f...              15   \n",
       "24                   ffffffffff alright way meet sooner               5   \n",
       "25    forced eat slice im really hungry tho sucks ma...              17   \n",
       "26                                lol always convincing               3   \n",
       "27    catch bus frying egg make tea eating moms left...              12   \n",
       "28     im back amp packing car ill let know theres room              10   \n",
       "29             ahhh work vaguely remember feel like lol               7   \n",
       "...                                                 ...             ...   \n",
       "2970  height confidence aeronautics professors wer c...              31   \n",
       "2971                  sary need tim bollox hurt lot tol               7   \n",
       "2972                            happy new year princess               4   \n",
       "2973                      ill text carlos let know hang               6   \n",
       "2974                        dont worry easy ingredients               4   \n",
       "2975             love u 2 little pocy bell sorry love u               9   \n",
       "2976                                      ok omw castor               3   \n",
       "2977  yar lor keep raining non stop u wan 2 go elsew...              11   \n",
       "2978  xmas offer latest motorola sonyericsson nokia ...              18   \n",
       "2979  u mean u almost done done wif sleeping tot u g...              22   \n",
       "2980  7 wonders world 7th 6th ur style 5th ur smile ...              26   \n",
       "2981                                    tonight yeah id               3   \n",
       "2982                                 eat fo lunch senor               4   \n",
       "2983  said right giggle saw u would possibly first p...              13   \n",
       "2984               break time one come n get stuff fr ì               9   \n",
       "2985  reply win å£100 weekly professional sport tige...              14   \n",
       "2986          im see cant see maybe reboot ym seen buzz               9   \n",
       "2987                                      still grinder               2   \n",
       "2988  1 polyphonic tone 4 ur mob every week txt pt2 ...              24   \n",
       "2989  love isnt decision feeling could decide love l...              13   \n",
       "2990  hot live fantasies call 08707509020 20p per mi...              20   \n",
       "2991                              ki didt see youkwhere               4   \n",
       "2992                                     im list buyers               3   \n",
       "2993  idea guess well work hour supposed leave since...              15   \n",
       "2994    mm entirely sure understood text hey ho weekend               8   \n",
       "2995  released vday shirts u put makes bottom half n...              12   \n",
       "2996                      knowhe watching film computer               4   \n",
       "2997                                        b4 thursday               2   \n",
       "2998                       oh phone phoned disconnected               4   \n",
       "2999                 id onluy matters getting offcampus               5   \n",
       "\n",
       "      nounCount  verbCount  \n",
       "0            10          1  \n",
       "1             4          0  \n",
       "2            13          3  \n",
       "3             3          0  \n",
       "4             1          4  \n",
       "5             9          8  \n",
       "6             3          2  \n",
       "7            12          4  \n",
       "8            11          6  \n",
       "9            11          3  \n",
       "10            3          8  \n",
       "11           11          2  \n",
       "12           15          1  \n",
       "13            6          7  \n",
       "14            4          0  \n",
       "15           11          2  \n",
       "16            1          1  \n",
       "17            5          4  \n",
       "18            5          1  \n",
       "19           14          0  \n",
       "20            1          1  \n",
       "21            2          5  \n",
       "22            3          1  \n",
       "23            7          0  \n",
       "24            3          1  \n",
       "25            4          7  \n",
       "26            0          1  \n",
       "27           11          4  \n",
       "28            3          4  \n",
       "29            3          2  \n",
       "...         ...        ...  \n",
       "2970         20          7  \n",
       "2971          3          2  \n",
       "2972          3          0  \n",
       "2973          1          4  \n",
       "2974          1          2  \n",
       "2975          1          0  \n",
       "2976          2          0  \n",
       "2977          6          1  \n",
       "2978         15          1  \n",
       "2979         12          5  \n",
       "2980         17          0  \n",
       "2981          1          1  \n",
       "2982          3          1  \n",
       "2983          3          5  \n",
       "2984          5          1  \n",
       "2985          8          3  \n",
       "2986          2          4  \n",
       "2987          1          1  \n",
       "2988         13          2  \n",
       "2989          5          5  \n",
       "2990         13          1  \n",
       "2991          4          0  \n",
       "2992          2          1  \n",
       "2993          4          6  \n",
       "2994          7          1  \n",
       "2995          3          3  \n",
       "2996          4          2  \n",
       "2997          2          0  \n",
       "2998          1          2  \n",
       "2999          4          1  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now read the data normally through the command .read_csv()\n",
    "processedData = pd.read_csv(\"pre.csv\", index_col = False)\n",
    "processedData = processedData.drop(\"Unnamed: 0\", axis = 1)\n",
    "processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3000x500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14076 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we go about doing the normal feature engineering\n",
    "#lets look at some advanced features\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def extraFeatures(processedData):\n",
    "    #lets create their objects\n",
    "    cvz = CountVectorizer()\n",
    "    #we will fit the clean data over here\n",
    "    cvz.fit(processedData[\"cleanText\"].values.astype('U'))\n",
    "    count_vectors = cvz.transform(processedData[\"cleanText\"].values.astype('U'))\n",
    "    word_tfidf = TfidfVectorizer(max_features = 500)\n",
    "    #we will fit the clean data over here\n",
    "    word_tfidf.fit(processedData[\"cleanText\"].values.astype('U'))\n",
    "    word_vectors_tfidf = word_tfidf.transform(processedData[\"cleanText\"].values.astype('U'))\n",
    "    return word_vectors_tfidf\n",
    "\n",
    "\n",
    "word_vectors_tfid = extraFeatures(processedData)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_vectors_tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we now havea lot of features to play with. We now have to combine it all\n",
    "# we will create a sparse matrix\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "#we have had a look at the processed data and we will choose the columns accordingly\n",
    "meta_features = [ 'cleanWordCount',\n",
    "       'nounCount', 'verbCount']\n",
    "feature_set1 = processedData[meta_features]\n",
    "train = hstack([word_vectors_tfid, csr_matrix(feature_set1)], \"csr\")\n",
    "train\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is time for classification, but before that we have to label encode the label column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "target = processedData[\"label\"].values\n",
    "target = LabelEncoder().fit_transform(target)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(train, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('modelDetailsAndSuccess.txt', 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.968\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.8986666666666666\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aviralsharma/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/aviralsharma/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/aviralsharma/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#we now run different models on it\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "model = LogisticRegression()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "model = svm.SVC()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "#ensemble methods\n",
    "model = ensemble.ExtraTreesClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME        CREATED                SIZE (MASTER) \r\n",
      "RESULTS     Less than a second ago 0B            \r\n",
      "CLEANDATA   52 minutes ago         450.9KiB      \r\n",
      "SMSTRAINING About an hour ago      268.4KiB      \r\n",
      "jup         3 hours ago            0B            \r\n",
      "test        24 hours ago           0B            \r\n",
      "prep2       27 hours ago           868.1KiB      \r\n",
      "prep        28 hours ago           555KiB        \r\n",
      "sms         29 hours ago           473.5KiB      \r\n",
      "possible    44 hours ago           55B           \r\n",
      "inference   44 hours ago           94B           \r\n",
      "kim         45 hours ago           1.465KiB      \r\n",
      "training    46 hours ago           3.882KiB      \r\n"
     ]
    }
   ],
   "source": [
    "#It is time to create the final repo and add the results into it\n",
    "!pachctl create repo RESULTS\n",
    "!pachctl list repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl put file RESULTS@master:modelDetailsAndSuccess.txt -f modelDetailsAndSuccess.txt --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4. Now that we have done the SMS spam analysis for for one version of rawData and one version of preprocessed\\n   data, we finally get to try what we have all been waiting for: APPLYING DATA VERSIONING.\\n   Just for reference purposes, I will be refering to the 4 forms of raw data as RAW1(3000 rows) RAW2(5572 rows)\\n   RAW3(5000 rows) and RAW4(4000 rows) and I will be refereing to the more advanced preproccesing as PREPROCESS1\\n   and the lesser preprocessing method as PREPROCESS2. \\n   NOTE: THE PREPROCESSING EXAMPLES USED HERE CAN ALSO BE IMPLIED AS AN ANALOGY FOR MODELS. EVERY MODEL CAN BE\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4. Now that we have done the SMS spam analysis for for one version of rawData and one version of preprocessed\n",
    "   data, we finally get to try what we have all been waiting for: APPLYING DATA VERSIONING.\n",
    "   Just for reference purposes, I will be refering to the 4 forms of raw data as RAW1(3000 rows) RAW2(5572 rows)\n",
    "   RAW3(5000 rows) and RAW4(4000 rows) and I will be refereing to the more advanced preproccesing as PREPROCESS1\n",
    "   and the lesser preprocessing method as PREPROCESS2. \n",
    "   NOTE: THE PREPROCESSING EXAMPLES USED HERE CAN ALSO BE IMPLIED AS AN ANALOGY FOR MODELS. EVERY MODEL CAN BE\n",
    "   CODED IN SUCH A WAY THAT CERTAIN VERSIONS ARE MORE ADVANCED(for lack of a better word ~ compact maybe?) THAN \n",
    "   OTHERS\n",
    "   I will be providing the results of all of it the end of it all\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO      BRANCH COMMIT                           PARENT                           STARTED           DURATION           SIZE     \r\n",
      "CLEANDATA master a6f41f8ba4a54824a5a9e4bf948a9bb5 b290f1d7f77c487cb4bcc066ba731ab5 58 minutes ago    Less than a second 450.9KiB \r\n",
      "CLEANDATA master b290f1d7f77c487cb4bcc066ba731ab5 <none>                           About an hour ago Less than a second 483.7KiB \r\n"
     ]
    }
   ],
   "source": [
    "#RAW1 PREPROCESS 1\n",
    "#we first need to access the previous version of the CLEANDATA\n",
    "!pachctl list commit CLEANDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl get file CLEANDATA@b290f1d7f77c487cb4bcc066ba731ab5:processedData.csv > raw1pre1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now read the data normally through the command .read_csv()\n",
    "rawData = pd.read_csv(\"raw1pre1.csv\", index_col = False)\n",
    "rawData = rawData.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9706666666666667\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.964\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.9293333333333333\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.964\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aviralsharma/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/aviralsharma/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/aviralsharma/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def extraFeatures(processedData):\n",
    "    #lets create their objects\n",
    "    cvz = CountVectorizer()\n",
    "    #we will fit the clean data over here\n",
    "    cvz.fit(processedData[\"cleanText\"].values.astype('U'))\n",
    "    count_vectors = cvz.transform(processedData[\"cleanText\"].values.astype('U'))\n",
    "    word_tfidf = TfidfVectorizer(max_features = 500)\n",
    "    #we will fit the clean data over here\n",
    "    word_tfidf.fit(processedData[\"cleanText\"].values.astype('U'))\n",
    "    word_vectors_tfidf = word_tfidf.transform(processedData[\"cleanText\"].values.astype('U'))\n",
    "    return word_vectors_tfidf\n",
    "\n",
    "\n",
    "word_vectors_tfid = extraFeatures(rawData)\n",
    "#we have had a look at the processed data and we will choose the columns accordingly\n",
    "meta_features = [ 'rawWordCount', 'cleanWordCount',\n",
    "       'characterCount', 'characterCountWithoutSpace', 'digitOccurrece',\n",
    "       'nounCount', 'verbCount']\n",
    "feature_set1 = rawData[meta_features]\n",
    "train = hstack([word_vectors_tfid, csr_matrix(feature_set1)], \"csr\")\n",
    "\n",
    "\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(train, target)\n",
    "\n",
    "f = open('modelDetailsAndSuccess.txt', 'r+')\n",
    "#we now run different models on it\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "model = LogisticRegression()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "model = svm.SVC()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "#ensemble methods\n",
    "model = ensemble.ExtraTreesClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(validation_x)\n",
    "print(accuracy_score(preds, validation_y))\n",
    "print(model)\n",
    "f.write(str(accuracy_score(preds, validation_y)))\n",
    "f.write(str(model))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forgot to concise it, putting everything in a big function now:\n",
    "def concise(rawData, meta_features):\n",
    "    word_vectors_tfid = extraFeatures(rawData)\n",
    "    #we have had a look at the processed data and we will choose the columns accordingly\n",
    "    feature_set1 = rawData[meta_features]\n",
    "    train = hstack([word_vectors_tfid, csr_matrix(feature_set1)], \"csr\")\n",
    "\n",
    "\n",
    "    train_x, validation_x, train_y, validation_y = train_test_split(train, target)\n",
    "\n",
    "    f = open('modelDetailsAndSuccess.txt', 'r+')\n",
    "    #we now run different models on it\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(validation_x)\n",
    "    print(accuracy_score(preds, validation_y))\n",
    "    print(model)\n",
    "    f.write(str(accuracy_score(preds, validation_y)))\n",
    "    f.write(str(model))\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(validation_x)\n",
    "    print(accuracy_score(preds, validation_y))\n",
    "    print(model)\n",
    "    f.write(str(accuracy_score(preds, validation_y)))\n",
    "    f.write(str(model))\n",
    "    model = svm.SVC()\n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(validation_x)\n",
    "    print(accuracy_score(preds, validation_y))\n",
    "    print(model)\n",
    "    f.write(str(accuracy_score(preds, validation_y)))\n",
    "    f.write(str(model))\n",
    "    #ensemble methods\n",
    "    model = ensemble.ExtraTreesClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(validation_x)\n",
    "    print(accuracy_score(preds, validation_y))\n",
    "    print(model)\n",
    "    f.write(str(accuracy_score(preds, validation_y)))\n",
    "    f.write(str(model))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO        BRANCH COMMIT                           PARENT                           STARTED     DURATION           SIZE     \r\n",
      "SMSTRAINING master 1c81adf333904bb8afc7175474f27a21 7f18d48fa86a401896ed2adb0f1fa118 2 hours ago Less than a second 268.4KiB \r\n",
      "SMSTRAINING master 7f18d48fa86a401896ed2adb0f1fa118 534750817c0846639aeb930432a45d90 2 hours ago Less than a second 494.2KiB \r\n",
      "SMSTRAINING master 534750817c0846639aeb930432a45d90 d5627bffdfb34ea0acbbc53388e4d6b0 2 hours ago Less than a second 444.5KiB \r\n",
      "SMSTRAINING master d5627bffdfb34ea0acbbc53388e4d6b0 <none>                           2 hours ago Less than a second 354.6KiB \r\n"
     ]
    }
   ],
   "source": [
    "#Now let us tackle RAW 2, PREPROCESS 1 & 2\n",
    "m1  = [ 'rawWordCount', 'cleanWordCount',\n",
    "       'characterCount', 'characterCountWithoutSpace', 'digitOccurrece',\n",
    "       'nounCount', 'verbCount']\n",
    "m2 = [ 'cleanWordCount',\n",
    "       'nounCount', 'verbCount']\n",
    "\n",
    "#again lets look at the commits of TRAINING\n",
    "!pachctl list commit SMSTRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl get file SMSTRAINING@7f18d48fa86a401896ed2adb0f1fa118:raw.csv >raw2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now read the data normally through the command .read_csv()\n",
    "rawData = pd.read_csv(\"raw2.csv\", index_col = False)\n",
    "rawData = rawData.drop(\"Unnamed: 0\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDataPre1 = preProcessAndFeature(rawData)\n",
    "rawDataPre2 = preProcessAndFeatureVersion2(rawData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9741564967695621\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.9791816223977028\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.9519023689877961\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.9827709978463748\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "0.9791816223977028\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.9720028715003589\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.9511844938980617\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.9770279971284996\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "concise(rawDataPre1, m1)\n",
    "concise(rawDataPre1, m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: it is pretty obvious that I am not storing the preprocessed data in CLEANDATA repo nor am I storing the other\\n      results in RESULTS as that would make this notebook even longer. As a result, I am just focusing on the data\\n      versioning for just one repo. I already showed the data versioning for CLEANDATA for RAW1. It is the same concept\\n      for all. look at the commits for each repo and focus on the commit ID.\\n'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NOTE: it is pretty obvious that I am not storing the preprocessed data in CLEANDATA repo nor am I storing the other\n",
    "      results in RESULTS as that would make this notebook even longer. As a result, I am just focusing on the data\n",
    "      versioning for just one repo. I already showed the data versioning for CLEANDATA for RAW1. It is the same concept\n",
    "      for all. look at the commits for each repo and focus on the commit ID.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO        BRANCH COMMIT                           PARENT                           STARTED     DURATION           SIZE     \r\n",
      "SMSTRAINING master 1c81adf333904bb8afc7175474f27a21 7f18d48fa86a401896ed2adb0f1fa118 3 hours ago Less than a second 268.4KiB \r\n",
      "SMSTRAINING master 7f18d48fa86a401896ed2adb0f1fa118 534750817c0846639aeb930432a45d90 3 hours ago Less than a second 494.2KiB \r\n",
      "SMSTRAINING master 534750817c0846639aeb930432a45d90 d5627bffdfb34ea0acbbc53388e4d6b0 3 hours ago Less than a second 444.5KiB \r\n",
      "SMSTRAINING master d5627bffdfb34ea0acbbc53388e4d6b0 <none>                           3 hours ago Less than a second 354.6KiB \r\n"
     ]
    }
   ],
   "source": [
    "#Now let us tackle RAW 3, PREPROCESS 1 & 2\n",
    "!pachctl list commit SMSTRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl get file SMSTRAINING@534750817c0846639aeb930432a45d90:raw.csv >raw3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now read the data normally through the command .read_csv()\n",
    "rawData = pd.read_csv(\"raw3.csv\", index_col = False)\n",
    "rawData = rawData.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.976\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.936\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.9792\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "0.9688\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.9696\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.9064\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.9656\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rawDataPre1 = preProcessAndFeature(rawData)\n",
    "rawDataPre2 = preProcessAndFeatureVersion2(rawData)\n",
    "concise(rawDataPre1, m1)\n",
    "concise(rawDataPre2, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us tackle RAW 4, PREPROCESS 1 & 2\n",
    "!pachctl get file SMSTRAINING@d5627bffdfb34ea0acbbc53388e4d6b0:raw.csv >raw_4.csv\n",
    "#Now read the data normally through the command .read_csv()\n",
    "rawData = pd.read_csv(\"raw_4.csv\", index_col = False)\n",
    "rawData = rawData.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.973\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.927\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.979\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "0.968\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.965\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.901\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "0.966\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rawDataPre1 = preProcessAndFeature(rawData)\n",
    "rawDataPre2 = preProcessAndFeatureVersion2(rawData)\n",
    "concise(rawDataPre1, m1)\n",
    "concise(rawDataPre2, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConclusion (Finally :D ):\\nThe advantage of data versioning might not have been that visible from this experiment but that may be because\\n1. the data set is too small\\n2. I played around the data-set and the process related to it (namely:preprocessing and feature engineering)\\n   The difference might be more subtle if we play around with the model instead which is also possible\\n   \\nThe results:\\nRAW1:\\nPREPROCESS 2\\n0.9666666666666667\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.968LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.8986666666666666\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.972\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n                     \\nPREPROCESS 1\\n0.9706666666666667\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.964\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.9293333333333333\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.964\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\u200b\\nRAW2:\\n\\u200b\\nPREPROCESS1:\\n0.9720028715003589\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.9720028715003589\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.9339554917444365\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.9813352476669059\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\u200b\\nPREPROCESS2:\\n0.9705671213208902\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.9741564967695621\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.9023689877961235\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.9712849964106246\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\u200b\\nRAW3:\\n\\u200b\\nPREPROCESS1:\\n0.9648\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.9696\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.944\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.9808\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\u200b\\nPREPROCESS2:\\n0.9648\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.9712\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.9056\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.9768\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\nRAW4:\\n\\nPREPROCESS1:\\n0.982\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.975\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.945\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.976\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\nPREPROCESS2:\\n0.965\\nMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\\n0.967\\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l2',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\\n0.907\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\\n    shrinking=True, tol=0.001, verbose=False)\\n0.975\\nExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n                     max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                     min_impurity_decrease=0.0, min_impurity_split=None,\\n                     min_samples_leaf=1, min_samples_split=2,\\n                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\\n                     oob_score=False, random_state=None, verbose=0,\\n                     warm_start=False)\\n\\nRAW 2 (preprocess 1) which was the best data set performed the best for ensembling with an accuracy of \\n0.9813352476669059 which is what I accepted from the start.\\n\""
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Conclusion (Finally :D ):\n",
    "The advantage of data versioning might not have been that visible from this experiment but that may be because\n",
    "1. the data set is too small\n",
    "2. I played around the data-set and the process related to it (namely:preprocessing and feature engineering)\n",
    "   The difference might be more subtle if we play around with the model instead which is also possible\n",
    "   \n",
    "The results:\n",
    "RAW1:\n",
    "PREPROCESS 2\n",
    "0.9666666666666667\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.968LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.8986666666666666\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.972\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "                     \n",
    "PREPROCESS 1\n",
    "0.9706666666666667\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.964\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.9293333333333333\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.964\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "RAW2:\n",
    "​\n",
    "PREPROCESS1:\n",
    "0.9720028715003589\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.9720028715003589\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.9339554917444365\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.9813352476669059\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "PREPROCESS2:\n",
    "0.9705671213208902\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.9741564967695621\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.9023689877961235\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.9712849964106246\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "RAW3:\n",
    "​\n",
    "PREPROCESS1:\n",
    "0.9648\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.9696\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.944\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.9808\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "PREPROCESS2:\n",
    "0.9648\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.9712\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.9056\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.9768\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "​\n",
    "RAW4:\n",
    "​\n",
    "PREPROCESS1:\n",
    "0.982\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.975\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.945\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.976\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "PREPROCESS2:\n",
    "0.965\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "0.967\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "0.907\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "0.975\n",
    "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "​\n",
    "​\n",
    "​\n",
    "​\n",
    "​\n",
    "RAW 2 (preprocess 1) which was the best data set performed the best for ensembling with an accuracy of \n",
    "0.9813352476669059 which is what I accepted from the start.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
